{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#load model\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from h5_utils import h5read, h5disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = h5read(\"../symmetry_project/dataset/dataset.h5\", \"images\")\n",
    "obj =  h5read(\"../symmetry_project/dataset/dataset.h5\", \"obj\")\n",
    "ost =  h5read(\"../symmetry_project/dataset/dataset.h5\", \"ost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('muri1320', exist_ok=True)\n",
    "\n",
    "# Assuming dataset_transformed is a TensorDataset of shape [N, 3, 224, 224]\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=1, shuffle=False)\n",
    "\n",
    "# Optional: reverse any normalization (update if you used custom preprocessing)\n",
    "unnormalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "for i, (img_tensor,) in enumerate(data_loader):\n",
    "    img = unnormalize(img_tensor.squeeze(0))  # remove batch dimension and unnormalize\n",
    "    img = torch.clamp(img, 0, 1)  # clip to [0, 1] range\n",
    "    save_image(img, f'muri1320/image_{i:04d}.png')  # save with zero-padded index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 3, 256, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # Resize the image to 224x224 (input size for AlexNet)\n",
    "    transforms.Lambda(lambda x: (x / 255.0)),  # Rescale by dividing by 255\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "])\n",
    "\n",
    "dataset_tensor = torch.tensor(images, dtype=torch.float32)\n",
    "dataset_transformed = torch.stack([transform(img) for img in dataset_tensor])  # Apply transform to each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "import timm\n",
    "model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNormAct2d(\n",
       "    1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 320, 7, 7]) tensor(-33.5975) tensor(35.0662)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.blocks[6][0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "#np.save('./model_features/efficientnet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 512, 7, 7]) tensor(0.) tensor(6.3313)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet18_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1320, 25088])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_features.reshape(1320, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"model_features/resnet18_l2_eps3.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "# Extract the nested state_dict\n",
    "state_dict = checkpoint[\"model\"]\n",
    "\n",
    "# Remove the prefix: \"module.model.model.\"\n",
    "clean_state_dict = OrderedDict()\n",
    "prefix = \"module.model.\"\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(prefix):\n",
    "        new_k = k[len(prefix):]\n",
    "        clean_state_dict[new_k] = v\n",
    "\n",
    "# Try loading weights\n",
    "model.load_state_dict(clean_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 512, 7, 7]) tensor(0.) tensor(7.6611)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet18_robust_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "model = timm.create_model('resnet18.fb_ssl_yfcc100m_ft_in1k', pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 512, 7, 7]) tensor(0.) tensor(173.6028)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet18_ssl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3ac34f89ef4c6fa44fd71803669e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import timm\n",
    "model = timm.create_model('resnet50.fb_swsl_ig1b_ft_in1k', pretrained=True)\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 2048, 7, 7]) tensor(0.) tensor(211.0662)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet50_swsl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /users/smuzelle/.cache/torch/hub/facebookresearch_dino_main\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 2048, 7, 7]) tensor(0.) tensor(18.5285)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet50_ssl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet50_swsl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet152(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 1024, 14, 14]) tensor(0.) tensor(5.7675)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer3[34].bn3.register_forward_hook(hook_fn) #layer3[35]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet152_2_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /users/smuzelle/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:01<00:00, 115MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet101(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 1024, 14, 14]) tensor(0.) tensor(15.1838)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer3[22].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet101_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30ece0cfe7c44f89b1c302be11a8728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/177M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = timm.create_model('resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k', pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 1024, 14, 14]) tensor(0.) tensor(3.8273)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer3[22].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet101_ssl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c87e509682403e92ab4aa2bec5ff21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/240 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e6eee4fdc04fff9c84f07492b4692b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c817254ce1354399a6ed1eade0fef93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef01f2675cf74690bb331f7bce4f5e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-small-patch4-window8-256\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/swinv2-small-patch4-window8-256\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 49, 768]) tensor(-114.8137) tensor(10.2390)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.swinv2.encoder.layers[3].blocks[0].layernorm_after.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/swin_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc799a83ecd4423b640ccb15b655592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/240 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c70e73bc5a44229f9b42f627158d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a251e92ada10467b86e4292859b1103b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027860140d6d4434946842aee732a43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Swinv2ForMaskedImageModeling were not initialized from the model checkpoint at microsoft/swinv2-small-patch4-window16-256 and are newly initialized: ['decoder.0.bias', 'decoder.0.weight', 'swinv2.embeddings.mask_token']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, Swinv2ForMaskedImageModeling\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-small-patch4-window16-256\")\n",
    "model = Swinv2ForMaskedImageModeling.from_pretrained(\n",
    "    \"microsoft/swinv2-small-patch4-window16-256\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 49, 768]) tensor(-11.7128) tensor(91.1493)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.swinv2.encoder.layers[3].blocks[0].layernorm_after.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/swin_ssl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer3[22].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet101_ssl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([2640, 256, 6, 6]) tensor(0.) tensor(29.3822)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features[12].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/alexnet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.densenet201(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 896, 7, 7]) tensor(-0.8038) tensor(2.5911)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features.transition3.pool.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/densenet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.densenet169(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 640, 7, 7]) tensor(-0.7527) tensor(1.9534)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features.transition3.pool.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/densenet169_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.densenet121(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.densenet161(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1538819/3532106386.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_features/densenet_l2_eps3.ckpt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import densenet161\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"model_features/densenet_l2_eps3.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "# Extract the nested state_dict\n",
    "state_dict = checkpoint[\"model\"]\n",
    "\n",
    "# Remove the prefix: \"module.model.model.\"\n",
    "clean_state_dict = OrderedDict()\n",
    "prefix = \"module.model.model.\"\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(prefix):\n",
    "        new_k = k[len(prefix):]\n",
    "        clean_state_dict[new_k] = v\n",
    "\n",
    "# Create DenseNet model\n",
    "model = densenet161()  # or 169/201/161 depending on match\n",
    "\n",
    "# Try loading weights\n",
    "model.load_state_dict(clean_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 1056, 7, 7]) tensor(-1.3439) tensor(2.0056)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features.transition3.pool.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/densenet161_robust_eps3_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 512, 7, 7]) tensor(-0.9936) tensor(1.8007)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features.transition3.pool.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/densenet121_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /users/smuzelle/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShuffleNetV2(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (stage2): Sequential(\n",
       "    (0): InvertedResidual(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=58, bias=False)\n",
       "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): InvertedResidual(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): InvertedResidual(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
       "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
       "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(464, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 464, 7, 7]) tensor(0.) tensor(4.7454)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.stage4.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/shufflenet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /users/smuzelle/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "from torchvision.models import densenet161\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"model_features/shufflenet_l2_eps3.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "# Extract the nested state_dict\n",
    "state_dict = checkpoint[\"model\"]\n",
    "\n",
    "# Remove the prefix: \"module.model.model.\"\n",
    "clean_state_dict = OrderedDict()\n",
    "prefix = \"module.model.model.\"\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(prefix):\n",
    "        new_k = k[len(prefix):]\n",
    "        clean_state_dict[new_k] = v\n",
    "\n",
    "# Try loading weights\n",
    "model.load_state_dict(clean_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 464, 7, 7]) tensor(0.) tensor(2.8035)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.stage4.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/shufflenet_robust_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.inception_v3(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 1280, 5, 5]) tensor(0.) tensor(20.1041)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.Mixed_7a.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/inceptionv3_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 197, 768]) tensor(-44.4042) tensor(34.4210)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.encoder.layers[6].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/vit_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name vit_small_patch16_224_dino to current vit_small_patch16_224.dino.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "model = timm.create_model(\"vit_small_patch16_224_dino\", pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 197, 384]) tensor(-2.0844) tensor(1.1553)\n"
     ]
    }
   ],
   "source": [
    "deolbatch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.blocks[6].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/vit_ssl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16_bn(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1538819/2104175007.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_features/vgg16_bn_l2_eps3.ckpt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original keys: ['module.normalizer.new_mean', 'module.normalizer.new_std', 'module.model.model.features.0.weight', 'module.model.model.features.0.bias', 'module.model.model.features.1.weight']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"model_features/vgg16_bn_l2_eps3.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "# Extract state_dict\n",
    "state_dict = checkpoint['model']  # this assumes your dict is under 'model'\n",
    "\n",
    "# Optionally, inspect first few keys\n",
    "print(\"Original keys:\", list(state_dict.keys())[:5])\n",
    "\n",
    "# Clean the keys to match the model definition\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(\"module.model.model.\"):\n",
    "        new_k = k.replace(\"module.model.model.\", \"\")\n",
    "    elif k.startswith(\"module.attacker.model.model.\"):\n",
    "        new_k = k.replace(\"module.attacker.model.model.\", \"\")\n",
    "    else:\n",
    "        continue  # Skip anything that doesn't match your intended model\n",
    "    new_state_dict[new_k] = v\n",
    "\n",
    "# Load cleaned state_dict into your model\n",
    "model.load_state_dict(new_state_dict)  # strict=False lets you ignore unmatched keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 256, 28, 28]) tensor(0.) tensor(3.6927)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features[23].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/vgg16_robust_eps3_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100352"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.convnext_tiny(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 0, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 0 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 1, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 1 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 2, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 2 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 3, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 3 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 4, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 4 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 5, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 5 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 6, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 6 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 7, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 7 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 8, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 8 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 9, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 9 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 10, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 10 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 11, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 11 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 12, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 12 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 13, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 13 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 14, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 14 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 15, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 15 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 16, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 16 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 17, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 17 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 18, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 18 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 19, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 19 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 20, shape: torch.Size([40, 3, 224, 224])\n",
      "Hook fired at batch 20 with input torch.Size([40, 384, 14, 14]), and output torch.Size([40, 384, 14, 14])\n",
      "21\n",
      "torch.Size([1320, 384, 14, 14]) tensor(-1.7166) tensor(11.1413)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "batch_count = 0\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Hook fired at batch {batch_count} with input {input[0].shape}, and output {output.shape}\")\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features[5][4].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(f\"Running batch {batch_count}, shape: {images.shape}\")\n",
    "        _ = model(images)\n",
    "        batch_count += 1\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "print(len(output_features))\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/convnext_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f6d69349654be082071d3b089a3ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/115M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = timm.create_model('convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): NormMlpClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (pre_logits): Identity()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 0, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 0 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 1, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 1 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 2, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 2 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 3, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 3 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 4, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 4 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 5, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 5 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 6, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 6 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 7, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 7 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 8, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 8 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 9, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 9 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 10, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 10 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 11, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 11 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 12, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 12 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 13, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 13 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 14, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 14 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 15, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 15 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 16, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 16 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 17, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 17 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 18, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 18 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 19, shape: torch.Size([64, 3, 224, 224])\n",
      "Hook fired at batch 19 with input torch.Size([64, 384, 14, 14]), and output torch.Size([64, 384, 14, 14])\n",
      "Running batch 20, shape: torch.Size([40, 3, 224, 224])\n",
      "Hook fired at batch 20 with input torch.Size([40, 384, 14, 14]), and output torch.Size([40, 384, 14, 14])\n",
      "21\n",
      "torch.Size([1320, 384, 14, 14]) tensor(-14.0473) tensor(124.2143)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "batch_count = 0\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Hook fired at batch {batch_count} with input {input[0].shape}, and output {output.shape}\")\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.stages[2].blocks[4].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(f\"Running batch {batch_count}, shape: {images.shape}\")\n",
    "        _ = model(images)\n",
    "        batch_count += 1\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "print(len(output_features))\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/convnext_ssl_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 384, 14, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./model_features/convnext_features.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2640, torch.Size([384, 14, 14]), torch.Size([384, 14, 14]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_features), output_features[0].shape, output_features[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75264"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "384*14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75264/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.32.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /users/smuzelle/.local/lib/python3.11/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /users/smuzelle/.local/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /users/smuzelle/.local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.32.0-py3-none-any.whl (509 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.26.2\n",
      "    Uninstalling huggingface-hub-0.26.2:\n",
      "      Successfully uninstalled huggingface-hub-0.26.2\n",
      "Successfully installed hf-xet-1.1.2 huggingface-hub-0.32.0 regex-2024.11.6 tokenizers-0.21.1 transformers-4.52.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(48, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), groups=48, bias=False)\n",
       "        (normalization): BatchNorm2d(48, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(48, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(288, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False)\n",
       "          (normalization): BatchNorm2d(288, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(48, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(288, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n",
       "          (normalization): BatchNorm2d(288, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(88, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(528, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False)\n",
       "          (normalization): BatchNorm2d(528, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(88, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(528, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False)\n",
       "          (normalization): BatchNorm2d(528, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(136, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(816, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), groups=816, bias=False)\n",
       "          (normalization): BatchNorm2d(816, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(136, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(816, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), groups=816, bias=False)\n",
       "          (normalization): BatchNorm2d(816, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(224, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1344, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), groups=1344, bias=False)\n",
       "          (normalization): BatchNorm2d(1344, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(224, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1344, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), groups=1344, bias=False)\n",
       "          (normalization): BatchNorm2d(1344, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(448, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1792, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=True)\n",
       "  (classifier): Linear(in_features=1792, out_features=1001, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"google/mobilenet_v2_1.4_224\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"google/mobilenet_v2_1.4_224\", trust_remote_code=True, use_safetensors=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "model = mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original keys: ['module.normalizer.new_mean', 'module.normalizer.new_std', 'module.model.model.features.0.0.weight', 'module.model.model.features.0.1.weight', 'module.model.model.features.0.1.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1538819/2312309495.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_features/mobilenet_l2_eps3.ckpt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"model_features/mobilenet_l2_eps3.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "# Extract state_dict\n",
    "state_dict = checkpoint['model']  # this assumes your dict is under 'model'\n",
    "\n",
    "# Optionally, inspect first few keys\n",
    "print(\"Original keys:\", list(state_dict.keys())[:5])\n",
    "\n",
    "# Clean the keys to match the model definition\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(\"module.model.model.\"):\n",
    "        new_k = k.replace(\"module.model.model.\", \"\")\n",
    "    elif k.startswith(\"module.attacker.model.model.\"):\n",
    "        new_k = k.replace(\"module.attacker.model.model.\", \"\")\n",
    "    else:\n",
    "        continue  # Skip anything that doesn't match your intended model\n",
    "    new_state_dict[new_k] = v\n",
    "\n",
    "# Load cleaned state_dict into your model\n",
    "model.load_state_dict(new_state_dict)  # strict=False lets you ignore unmatched keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([1320, 96, 14, 14]) tensor(-5.2174) tensor(5.0877)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features[12].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/mobilenet_v2_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18424"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "94*14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (1.0.11)\n",
      "Requirement already satisfied: torch in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from timm) (2.5.1)\n",
      "Requirement already satisfied: torchvision in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from timm) (0.20.1)\n",
      "Requirement already satisfied: pyyaml in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from timm) (0.26.2)\n",
      "Requirement already satisfied: safetensors in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from timm) (0.4.5)\n",
      "Requirement already satisfied: filelock in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from huggingface_hub->timm) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /users/smuzelle/.local/lib/python3.11/site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in /users/smuzelle/.local/lib/python3.11/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /users/smuzelle/.local/lib/python3.11/site-packages (from torchvision->timm) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torchvision->timm) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /users/smuzelle/.local/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c132ef87a340a9af86b39bffbfeb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/17.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): ReLU6(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Identity()\n",
       "  (bn2): Identity()\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# Load MobileNetV1 with width multiplier 0.75\n",
    "model = timm.create_model('mobilenetv1_100.ra4_e3600_r224_in1k', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "# Helper function to move models to GPU or CPU\n",
    "def move_model_to_device(model):\n",
    "    \"\"\"Move the model to GPU if available, otherwise to CPU.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU (CUDA)\")\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    return model\n",
    "    \n",
    "def load_model(model_name):\n",
    "    model_urls = {\n",
    "        'resnet50_trained_on_SIN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/6f41d2e86fc60566f78de64ecff35cc61eb6436f/resnet50_train_60_epochs-c8e5653e.pth.tar',\n",
    "        'resnet50_trained_on_SIN_and_IN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/60b770e128fffcbd8562a3ab3546c1a735432d03/resnet50_train_45_epochs_combined_IN_SF-2a0d100e.pth.tar',\n",
    "        'resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/60b770e128fffcbd8562a3ab3546c1a735432d03/resnet50_finetune_60_epochs_lr_decay_after_30_start_resnet50_train_45_epochs_combined_IN_SF-ca06340c.pth.tar',\n",
    "    }\n",
    "\n",
    "    if \"resnet50\" in model_name:\n",
    "        print(\"Using the ResNet50 architecture.\")\n",
    "        model = torchvision.models.resnet50(pretrained=False)\n",
    "        model = move_model_to_device(model)\n",
    "        checkpoint = model_zoo.load_url(model_urls[model_name], map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    elif \"vgg16\" in model_name:\n",
    "        print(\"Using the VGG-16 architecture.\")\n",
    "        filepath = \"./vgg16_train_60_epochs_lr0.01-6c6fcc9f.pth.tar\"\n",
    "        assert os.path.exists(filepath), \"Please download the VGG model manually from https://drive.google.com/drive/folders/1A0vUWyU6fTuc-xWgwQQeBvzbwi6geYQK\"\n",
    "        model = torchvision.models.vgg16(pretrained=False)\n",
    "        model.features = move_model_to_device(model.features)\n",
    "        checkpoint = torch.load(filepath, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    elif \"alexnet\" in model_name:\n",
    "        print(\"Using the AlexNet architecture.\")\n",
    "        filepath = \"./alexnet_train_60_epochs_lr0.001-b4aa5238.pth.tar\"\n",
    "        assert os.path.exists(filepath), \"Please download the AlexNet model manually from https://drive.google.com/drive/folders/1GnxcR6HUyPfRWAmaXwuiMdAMKlL1shTn\"\n",
    "        model = torchvision.models.alexnet(pretrained=False)\n",
    "        model.features = move_model_to_device(model.features)\n",
    "        checkpoint = torch.load(filepath, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model architecture.\")\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/brainscore_core/metrics/__init__.py:16: FutureWarning: xarray subclass Score should explicitly define __slots__\n",
      "  class Score(DataAssembly):\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from brainscore_vision.model_helpers.activations.pytorch import load_preprocess_images\n",
    "from brainscore_vision.model_helpers.activations.pytorch import PytorchWrapper\n",
    "from brainscore_vision.model_helpers.check_submission import check_models\n",
    "\n",
    "def get_model(name):\n",
    "    \"\"\"\n",
    "    This method fetches an instance of a base model. The instance has to be callable and return a xarray object,\n",
    "    containing activations. There exist standard wrapper implementations for common libraries, like pytorch and\n",
    "    keras. Checkout the examples folder, to see more. For custom implementations check out the implementation of the\n",
    "    wrappers.\n",
    "    :param name: the name of the model to fetch\n",
    "    :return: the model instance\n",
    "    \"\"\"\n",
    "    assert name == 'resnet50-SIN_IN_IN'\n",
    "    model = load_model(\"resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN\")\n",
    "    preprocessing = functools.partial(load_preprocess_images, image_size=224)\n",
    "    wrapper = PytorchWrapper(identifier='name', model=model, preprocessing=preprocessing)\n",
    "    wrapper.image_size = 224\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the ResNet50 architecture.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "model = get_model('resnet50-SIN_IN_IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model._model.module\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([40, 2048, 7, 7])\n",
      "torch.Size([1320, 2048, 7, 7]) tensor(0.) tensor(3.2473)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(output.shape)\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnetSIN_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 512, 7, 7])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([40, 512, 14, 14])\n",
      "torch.Size([40, 512, 7, 7])\n",
      "torch.Size([40, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(output_features)):\n",
    "    print(output_features[t].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting CORnet@ git+https://github.com/dicarlolab/CORnet.git (from -r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 7))\n",
      "  Cloning https://github.com/dicarlolab/CORnet.git to /tmp/pip-install-17lqpbya/cornet_15ce99f77d61474e8b4fd8390efa5c8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/dicarlolab/CORnet.git /tmp/pip-install-17lqpbya/cornet_15ce99f77d61474e8b4fd8390efa5c8d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/dicarlolab/CORnet.git to commit d0cc17d4b34ad44dedb01683b70eafd15515adad\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torchvision in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from -r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 1)) (0.20.1)\n",
      "Requirement already satisfied: torch in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from -r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (2.5.1)\n",
      "Requirement already satisfied: pandas in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from -r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: xarray in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from -r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 4)) (2022.3.0)\n",
      "Requirement already satisfied: numpy in /users/smuzelle/.local/lib/python3.11/site-packages (from -r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: scipy in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from -r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torchvision->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 1)) (11.0.0)\n",
      "Requirement already satisfied: filelock in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from sympy==1.13.1->torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from pandas->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from pandas->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from pandas->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /users/smuzelle/.local/lib/python3.11/site-packages (from xarray->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: tqdm in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from CORnet@ git+https://github.com/dicarlolab/CORnet.git->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: fire in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from CORnet@ git+https://github.com/dicarlolab/CORnet.git->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /users/smuzelle/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /users/smuzelle/.local/lib/python3.11/site-packages (from fire->CORnet@ git+https://github.com/dicarlolab/CORnet.git->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 7)) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /users/smuzelle/.local/lib/python3.11/site-packages (from jinja2->torch->-r /cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/requirements.txt (line 2)) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/model.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weights_path, map_location=lambda storage, loc: storage)  # map onto cpu\n"
     ]
    }
   ],
   "source": [
    "from brainscore_vision import load_model\n",
    "model = load_model(\"CORnet-S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RecordingTarget',\n",
       " 'Task',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_identifier',\n",
       " '_visual_degrees',\n",
       " 'activations_model',\n",
       " 'behavior_model',\n",
       " 'do_behavior',\n",
       " 'identifier',\n",
       " 'layers',\n",
       " 'look_at',\n",
       " 'look_at_cached',\n",
       " 'recording_layers',\n",
       " 'recording_time_bins',\n",
       " 'start_recording',\n",
       " 'start_task',\n",
       " 'time_mapping',\n",
       " 'visual_degrees']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V1.output-t0',\n",
       " 'V2.output-t0',\n",
       " 'V2.output-t1',\n",
       " 'V4.output-t0',\n",
       " 'V4.output-t1',\n",
       " 'V4.output-t2',\n",
       " 'V4.output-t3',\n",
       " 'IT.output-t0',\n",
       " 'IT.output-t1',\n",
       " 'decoder.avgpool-t0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.activations_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (V1): Sequential(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (nonlin1): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (nonlin2): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "  )\n",
       "  (V2): CORblock_S(\n",
       "    (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (nonlin2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin3): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "    (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm1_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (V4): CORblock_S(\n",
       "    (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (nonlin2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin3): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "    (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm1_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm1_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm1_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (IT): CORblock_S(\n",
       "    (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (nonlin2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin3): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "    (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm1_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten()\n",
       "    (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "    (output): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recording = 'IT.output-t0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8382f0ee6cd4f80b130220a6f248d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "activations:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/symmetry/lib/python3.11/site-packages/PIL/Image.py:3475\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3475\u001b[0m     fp\u001b[39m.\u001b[39;49mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m   3476\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# CORnet model returns an xarray.DataArray\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m result \u001b[39m=\u001b[39m model(images, layers\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mIT.output-t0\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m result_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mvalues)  \u001b[39m# convert to tensor\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(result_tensor\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/pytorch.py:41\u001b[0m, in \u001b[0;36mPytorchWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):  \u001b[39m# cannot assign __call__ as attribute due to Python convention\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extractor(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/core.py:61\u001b[0m, in \u001b[0;36mActivationsExtractorHelper.__call__\u001b[0;34m(self, stimuli, layers, stimuli_identifier, number_of_trials, require_variance)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     function_call \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrom_paths, stimuli_paths\u001b[39m=\u001b[39mstimuli)\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m function_call(\n\u001b[1;32m     62\u001b[0m     layers\u001b[39m=\u001b[39;49mlayers,\n\u001b[1;32m     63\u001b[0m     stimuli_identifier\u001b[39m=\u001b[39;49mstimuli_identifier,\n\u001b[1;32m     64\u001b[0m     require_variance\u001b[39m=\u001b[39;49mrequire_variance)\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/models/cornet_s/helpers/helpers.py:179\u001b[0m, in \u001b[0;36mTemporalExtractor.from_paths\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_paths\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 179\u001b[0m     raw_activations \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(TemporalExtractor, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfrom_paths(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    180\u001b[0m     \u001b[39m# introduce time dimension\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     regions \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/core.py:104\u001b[0m, in \u001b[0;36mActivationsExtractorHelper.from_paths\u001b[0;34m(self, stimuli_paths, layers, stimuli_identifier, require_variance)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[39m# When we are not asked for varying responses but receive `stimuli_paths` duplicates (e.g. multiple trials),\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# we first reduce them to only the paths that need to be run individually, compute activations for those,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# and then expand the activations to all paths again. This is done here, before storing, so that we only\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39m# store the reduced activations.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     reduced_paths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reduce_paths(stimuli_paths)\n\u001b[0;32m--> 104\u001b[0m     activations \u001b[39m=\u001b[39m fnc(layers\u001b[39m=\u001b[39;49mlayers, stimuli_paths\u001b[39m=\u001b[39;49mreduced_paths, require_variance\u001b[39m=\u001b[39;49mrequire_variance)\n\u001b[1;32m    105\u001b[0m     activations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_paths(activations, original_paths\u001b[39m=\u001b[39mstimuli_paths)\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m activations\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/core.py:117\u001b[0m, in \u001b[0;36mActivationsExtractorHelper._from_paths\u001b[0;34m(self, layers, stimuli_paths, require_variance)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo layers passed to retrieve activations from\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mRunning stimuli\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m layer_activations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_activations_batched(stimuli_paths, layers\u001b[39m=\u001b[39;49mlayers, batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_size,\n\u001b[1;32m    118\u001b[0m                                                   require_variance\u001b[39m=\u001b[39;49mrequire_variance)\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mPackaging into assembly\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_package(layer_activations\u001b[39m=\u001b[39mlayer_activations, stimuli_paths\u001b[39m=\u001b[39mstimuli_paths, require_variance\u001b[39m=\u001b[39mrequire_variance)\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/core.py:170\u001b[0m, in \u001b[0;36mActivationsExtractorHelper._get_activations_batched\u001b[0;34m(self, paths, layers, batch_size, require_variance)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m# compute activations on the entire batch one microsaccade shift at a time.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m shift_number \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_microsaccade_helper\u001b[39m.\u001b[39mnumber_of_trials):\n\u001b[0;32m--> 170\u001b[0m     activations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batch_activations(inputs\u001b[39m=\u001b[39;49mbatch_inputs,\n\u001b[1;32m    171\u001b[0m                                               layer_names\u001b[39m=\u001b[39;49mlayers,\n\u001b[1;32m    172\u001b[0m                                               batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    173\u001b[0m                                               require_variance\u001b[39m=\u001b[39;49mrequire_variance,\n\u001b[1;32m    174\u001b[0m                                               trial_number\u001b[39m=\u001b[39;49mshift_number)\n\u001b[1;32m    176\u001b[0m     \u001b[39mfor\u001b[39;00m layer_name, layer_output \u001b[39min\u001b[39;00m activations\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    177\u001b[0m         batch_activations\u001b[39m.\u001b[39msetdefault(layer_name, [])\u001b[39m.\u001b[39mappend(layer_output)\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/core.py:200\u001b[0m, in \u001b[0;36mActivationsExtractorHelper._get_batch_activations\u001b[0;34m(self, inputs, layer_names, batch_size, require_variance, trial_number)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_batch_activations\u001b[39m(\u001b[39mself\u001b[39m, inputs, layer_names, batch_size: \u001b[39mint\u001b[39m, require_variance: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    198\u001b[0m                            trial_number: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    199\u001b[0m     inputs, num_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pad(inputs, batch_size)\n\u001b[0;32m--> 200\u001b[0m     preprocessed_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess(inputs)\n\u001b[1;32m    201\u001b[0m     preprocessed_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_microsaccade_helper\u001b[39m.\u001b[39mtranslate_images(images\u001b[39m=\u001b[39mpreprocessed_inputs,\n\u001b[1;32m    202\u001b[0m                                                                      image_paths\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    203\u001b[0m                                                                      trial_number\u001b[39m=\u001b[39mtrial_number,\n\u001b[1;32m    204\u001b[0m                                                                      require_variance\u001b[39m=\u001b[39mrequire_variance)\n\u001b[1;32m    205\u001b[0m     activations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_activations(preprocessed_inputs, layer_names)\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/pytorch.py:109\u001b[0m, in \u001b[0;36mload_preprocess_images\u001b[0;34m(image_filepaths, image_size, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_preprocess_images\u001b[39m(image_filepaths, image_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 109\u001b[0m     images \u001b[39m=\u001b[39m load_images(image_filepaths)\n\u001b[1;32m    110\u001b[0m     images \u001b[39m=\u001b[39m preprocess_images(images, image_size\u001b[39m=\u001b[39mimage_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m images\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/pytorch.py:115\u001b[0m, in \u001b[0;36mload_images\u001b[0;34m(image_filepaths)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_images\u001b[39m(image_filepaths):\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m [load_image(image_filepath) \u001b[39mfor\u001b[39;49;00m image_filepath \u001b[39min\u001b[39;49;00m image_filepaths]\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/pytorch.py:115\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_images\u001b[39m(image_filepaths):\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m [load_image(image_filepath) \u001b[39mfor\u001b[39;00m image_filepath \u001b[39min\u001b[39;00m image_filepaths]\n",
      "File \u001b[0;32m/cifs/data/tserre_lrs/projects/projects/prj_complex/neural_data/symmetry_project/vision/brainscore_vision/model_helpers/activations/pytorch.py:119\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(image_filepath)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(image_filepath):\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mwith\u001b[39;00m Image\u001b[39m.\u001b[39;49mopen(image_filepath) \u001b[39mas\u001b[39;00m pil_image:\n\u001b[1;32m    120\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pil_image\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mupper() \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pil_image\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mupper() \\\n\u001b[1;32m    121\u001b[0m                 \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pil_image\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mupper():  \u001b[39m# not binary and not alpha and not palletized\u001b[39;00m\n\u001b[1;32m    122\u001b[0m             \u001b[39m# work around to https://github.com/python-pillow/Pillow/issues/1144,\u001b[39;00m\n\u001b[1;32m    123\u001b[0m             \u001b[39m# see https://stackoverflow.com/a/30376272/2225200\u001b[39;00m\n\u001b[1;32m    124\u001b[0m             \u001b[39mreturn\u001b[39;00m pil_image\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.conda/envs/symmetry/lib/python3.11/site-packages/PIL/Image.py:3477\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fp\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m   3476\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation):\n\u001b[0;32m-> 3477\u001b[0m     fp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fp\u001b[39m.\u001b[39;49mread())\n\u001b[1;32m   3478\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3480\u001b[0m prefix \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mread(\u001b[39m16\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]  # [batch_size, 3, 224, 224]\n",
    "        print(images.shape)\n",
    "\n",
    "        # CORnet model returns an xarray.DataArray\n",
    "        result = model(images, layers=['IT.output-t0'])\n",
    "        result_tensor = torch.tensor(result.values)  # convert to tensor\n",
    "\n",
    "        print(result_tensor.shape)\n",
    "        output_features.append(result_tensor)\n",
    "\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/cornetS_2_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'brainscore_vision.stimuli'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb Cell 52\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbrainscore_vision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstimuli\u001b[39;00m \u001b[39mimport\u001b[39;00m StimulusSet\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m to_pil_image\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/get_features.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m stimuli \u001b[39m=\u001b[39m StimulusSet()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'brainscore_vision.stimuli'"
     ]
    }
   ],
   "source": [
    "from brainscore_vision.stimuli import StimulusSet\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "stimuli = StimulusSet()\n",
    "stimuli['image_id'] = list(range(len(images)))\n",
    "stimuli['image'] = [to_pil_image(img) for img in images]\n",
    "stimuli.image_paths = [None] * len(images)  # required field\n",
    "\n",
    "# Then call the wrapper\n",
    "result = model(stimuli, layers=['IT.output-t0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.create_model('nasnetalarge.tf_in1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NASNetALarge(\n",
       "  (conv0): ConvNormAct(\n",
       "    (conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNormAct2d(\n",
       "      96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "  )\n",
       "  (cell_stem_0): CellStem0(\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(42, 42, kernel_size=(5, 5), stride=(2, 2), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(96, 96, kernel_size=(7, 7), stride=(2, 2), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(96, 96, kernel_size=(7, 7), stride=(2, 2), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(96, 96, kernel_size=(5, 5), stride=(2, 2), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (cell_stem_1): CellStem1(\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): Sequential(\n",
       "      (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(84, 84, kernel_size=(5, 5), stride=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(84, 84, kernel_size=(7, 7), stride=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(84, 84, kernel_size=(7, 7), stride=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(84, 84, kernel_size=(5, 5), stride=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (cell_0): FirstCell(\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(336, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): Sequential(\n",
       "      (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_1): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(336, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_2): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_3): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_4): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_5): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (reduction_cell_0): ReductionCell0(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1008, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(336, 336, kernel_size=(5, 5), stride=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(336, 336, kernel_size=(7, 7), stride=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(336, 336, kernel_size=(7, 7), stride=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(336, 336, kernel_size=(5, 5), stride=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (cell_6): FirstCell(\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1344, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): Sequential(\n",
       "      (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_7): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1344, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_8): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_9): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_10): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_11): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (reduction_cell_1): ReductionCell1(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2016, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(672, 672, kernel_size=(7, 7), stride=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(672, 672, kernel_size=(7, 7), stride=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (cell_12): FirstCell(\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2688, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): Sequential(\n",
       "      (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_13): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2688, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_14): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_15): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_16): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_17): NormalCell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU(inplace=True)\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (act): ReLU(inplace=True)\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (last_linear): Linear(in_features=4032, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4032, 7, 7])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([40, 4032, 7, 7])\n",
      "torch.Size([1320, 4032, 7, 7]) tensor(-28.7157) tensor(22.0913)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(output.shape)\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.cell_12.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/nasnet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /users/smuzelle/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
      "100%|██████████| 49.7M/49.7M [00:00<00:00, 112MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.googlenet(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 512, 14, 14])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([40, 512, 14, 14])\n",
      "torch.Size([1320, 512, 14, 14]) tensor(0.) tensor(9.0918)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(output.shape)\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.inception4a.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/inceptionv1_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56c99913ae84034844856e408d879fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/345M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PNASNet5Large(\n",
       "  (conv_0): ConvNormAct(\n",
       "    (conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNormAct2d(\n",
       "      96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "  )\n",
       "  (cell_stem_0): CellStem0(\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(96, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(96, 96, kernel_size=(5, 5), stride=(2, 2), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(54, 54, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): Sequential(\n",
       "      (max_pool): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "      (conv): Conv2d(96, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(54, 54, kernel_size=(7, 7), stride=(2, 2), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(54, 54, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(54, 54, kernel_size=(5, 5), stride=(2, 2), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(54, 54, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(54, 54, kernel_size=(3, 3), stride=(2, 2), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2dSame(54, 54, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(54, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_stem_1): Cell(\n",
       "    (conv_prev_1x1): FactorizedReduction(\n",
       "      (act): ReLU()\n",
       "      (path_1): Sequential(\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(96, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (path_2): Sequential(\n",
       "        (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(96, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (final_path_bn): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(270, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(108, 108, kernel_size=(5, 5), stride=(2, 2), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(108, 108, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(108, 108, kernel_size=(7, 7), stride=(2, 2), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(108, 108, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(108, 108, kernel_size=(5, 5), stride=(2, 2), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(108, 108, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(108, 108, kernel_size=(3, 3), stride=(2, 2), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(108, 108, kernel_size=(3, 3), stride=(2, 2), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(108, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2dSame(108, 108, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(108, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_0): Cell(\n",
       "    (conv_prev_1x1): FactorizedReduction(\n",
       "      (act): ReLU()\n",
       "      (path_1): Sequential(\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(270, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (path_2): Sequential(\n",
       "        (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(270, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (final_path_bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(540, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_1): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(540, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1080, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_2): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1080, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1080, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_3): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1080, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1080, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_4): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1080, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(1080, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(432, 432, kernel_size=(5, 5), stride=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(432, 432, kernel_size=(7, 7), stride=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(432, 432, kernel_size=(5, 5), stride=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(432, 432, kernel_size=(3, 3), stride=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(432, 432, kernel_size=(3, 3), stride=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2dSame(432, 432, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_5): Cell(\n",
       "    (conv_prev_1x1): FactorizedReduction(\n",
       "      (act): ReLU()\n",
       "      (path_1): Sequential(\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(1080, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (path_2): Sequential(\n",
       "        (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(1080, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (final_path_bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2160, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_6): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2160, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2160, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_7): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2160, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2160, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_8): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2160, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(2160, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(864, 864, kernel_size=(5, 5), stride=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(864, 864, kernel_size=(7, 7), stride=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(864, 864, kernel_size=(5, 5), stride=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(864, 864, kernel_size=(3, 3), stride=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2dSame(864, 864, kernel_size=(3, 3), stride=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2dSame(864, 864, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_9): Cell(\n",
       "    (conv_prev_1x1): FactorizedReduction(\n",
       "      (act): ReLU()\n",
       "      (path_1): Sequential(\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(2160, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (path_2): Sequential(\n",
       "        (pad): ZeroPad2d((-1, 1, -1, 1))\n",
       "        (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        (conv): Conv2d(2160, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (final_path_bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4320, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_10): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4320, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4320, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_11): Cell(\n",
       "    (conv_prev_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4320, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): ActConvBn(\n",
       "      (act): ReLU()\n",
       "      (conv): Conv2d(4320, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_2_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (act_1): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_2): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(864, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(864, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (act): ReLU()\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (last_linear): Linear(in_features=4320, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = timm.create_model('pnasnet5large', pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 4320, 7, 7])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([40, 4320, 7, 7])\n",
      "torch.Size([1320, 4320, 7, 7]) tensor(-16.5427) tensor(19.8407)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(output.shape)\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.cell_8.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/pnasnet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /users/smuzelle/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n",
      "100%|██████████| 4.73M/4.73M [00:00<00:00, 25.5MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (6): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 192, 13, 13])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([40, 192, 13, 13])\n",
      "torch.Size([1320, 192, 13, 13]) tensor(0.) tensor(527.7888)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(output.shape)\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.features[9].expand3x3_activation.register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/squeezenet_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: robustbench in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: torch>=1.7.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (0.20.1)\n",
      "Requirement already satisfied: torchdiffeq in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (0.2.5)\n",
      "Requirement already satisfied: geotorch in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (0.3.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /users/smuzelle/.local/lib/python3.11/site-packages (from robustbench) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /users/smuzelle/.local/lib/python3.11/site-packages (from robustbench) (1.26.3)\n",
      "Requirement already satisfied: Jinja2~=3.1.2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (3.1.4)\n",
      "Requirement already satisfied: tqdm>=4.56.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (4.67.1)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (2.2.3)\n",
      "Requirement already satisfied: pyautoattack>=0.2.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (0.2.0)\n",
      "Requirement already satisfied: timm==1.0.9 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (1.0.9)\n",
      "Requirement already satisfied: gdown==5.1.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (5.1.0)\n",
      "Requirement already satisfied: pyyaml in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from robustbench) (6.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from gdown==5.1.0->robustbench) (4.12.3)\n",
      "Requirement already satisfied: filelock in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from gdown==5.1.0->robustbench) (3.16.1)\n",
      "Requirement already satisfied: huggingface_hub in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from timm==1.0.9->robustbench) (0.32.0)\n",
      "Requirement already satisfied: safetensors in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from timm==1.0.9->robustbench) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /users/smuzelle/.local/lib/python3.11/site-packages (from Jinja2~=3.1.2->robustbench) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from pandas>=1.3.5->robustbench) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from pandas>=1.3.5->robustbench) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from pandas>=1.3.5->robustbench) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests>=2.25.0->robustbench) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests>=2.25.0->robustbench) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests>=2.25.0->robustbench) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/smuzelle/.local/lib/python3.11/site-packages (from requests>=2.25.0->robustbench) (2023.11.17)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (4.12.2)\n",
      "Requirement already satisfied: networkx in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torch>=1.7.1->robustbench) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.7.1->robustbench) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torchvision>=0.8.2->robustbench) (11.0.0)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from torchdiffeq->robustbench) (1.14.1)\n",
      "Requirement already satisfied: six>=1.5 in /users/smuzelle/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->robustbench) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from beautifulsoup4->gdown==5.1.0->robustbench) (2.6)\n",
      "Requirement already satisfied: packaging>=20.9 in /users/smuzelle/.local/lib/python3.11/site-packages (from huggingface_hub->timm==1.0.9->robustbench) (23.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from huggingface_hub->timm==1.0.9->robustbench) (1.1.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages (from requests[socks]->gdown==5.1.0->robustbench) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade robustbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fra31/auto-attack\n",
      "  Cloning https://github.com/fra31/auto-attack to /tmp/pip-req-build-t614agmt\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fra31/auto-attack /tmp/pip-req-build-t614agmt\n",
      "  Resolved https://github.com/fra31/auto-attack to commit a39220048b3c9f2cca9a4d3a54604793c68eca7e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: autoattack\n",
      "  Building wheel for autoattack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autoattack: filename=autoattack-0.1-py3-none-any.whl size=36229 sha256=4e26ffd10c1bf74c08dbb8ca1e94bcb61b923f40c9cb6f397cddf0d811006ddf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cpkex6vw/wheels/e1/e8/28/65b2724d4c7740785979eb50bf5e1b3986ead22f6c32a87f8f\n",
      "Successfully built autoattack\n",
      "Installing collected packages: autoattack\n",
      "Successfully installed autoattack-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/fra31/auto-attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading models/imagenet/Linf/Salman2020Do_R50.pt (gdrive_id=1TmT5oGa1UvVjM3d-XeSj_XmKqBNRUg8r).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1TmT5oGa1UvVjM3d-XeSj_XmKqBNRUg8r\n",
      "From (redirected): https://drive.google.com/uc?id=1TmT5oGa1UvVjM3d-XeSj_XmKqBNRUg8r&confirm=t&uuid=70230091-58d1-4956-9bdc-197aa61ba839\n",
      "To: /files22_lrsresearch/CLPS_Serre_Lab/projects/prj_complex/neural_data/symmetry_idiosyncracy/models/imagenet/Linf/Salman2020Do_R50.pt\n",
      "100%|██████████| 103M/103M [00:01<00:00, 62.8MB/s] \n",
      "/users/smuzelle/.conda/envs/symmetry/lib/python3.11/site-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (normalize): ImageNormalizer(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from robustbench.model_zoo.enums import BenchmarkDataset\n",
    "from robustbench import load_model\n",
    "\n",
    "model = load_model(\n",
    "    model_name='Salman2020Do_R50',\n",
    "    dataset=BenchmarkDataset.imagenet,\n",
    "    threat_model='Linf'\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainscore_vision.model_helpers.check_submission import check_models\n",
    "from brainscore_vision.model_helpers.activations.pytorch import PytorchWrapper\n",
    "from brainscore_vision.model_helpers.activations.pytorch import load_preprocess_images\n",
    "import torchvision\n",
    "import functools\n",
    "import torch\n",
    "import os\n",
    "from torchvision.models import resnet50\n",
    "from brainscore_vision.model_helpers.s3 import load_weight_file\n",
    "\n",
    "\n",
    "def get_model(name):\n",
    "    \"\"\"\n",
    "    This method fetches an instance of a base model. The instance has to be callable and return a xarray object,\n",
    "    containing activations. There exist standard wrapper implementations for common libraries, like pytorch and\n",
    "    keras. Checkout the examples folder, to see more. For custom implementations check out the implementation of the\n",
    "    wrappers.\n",
    "    :param name: the name of the model to fetch\n",
    "    :return: the model instance\n",
    "    \"\"\"\n",
    "    assert name == 'resnet50_robust_l2_eps1'\n",
    "\n",
    "    model = resnet50()\n",
    "    weights_path = load_weight_file(bucket=\"brainscore-storage\", folder_name=\"brainscore-vision/models\",\n",
    "                                relative_path=\"resnet50_robust_l2_eps1/resnet50_l2_eps1.ckpt\",\n",
    "                                version_id=\"null\",\n",
    "                                sha1=\"c75d68b7509f9d3829663ca3b627d4265fa9f588\")\n",
    "    sd = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "    sd_processed = {}\n",
    "    for k, v in sd['model'].items():\n",
    "        if ('attacker' not in k) and ('model' in k):\n",
    "            sd_processed[k[13:]] = v\n",
    "    model.load_state_dict(sd_processed)\n",
    "    preprocessing = functools.partial(load_preprocess_images, image_size=224)\n",
    "    wrapper = PytorchWrapper(identifier='resnet50_robust_l2_eps1', model=model, preprocessing=preprocessing)\n",
    "    wrapper.image_size = 224\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2235464/3699088425.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(weights_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model('resnet50_robust_l2_eps1')\n",
    "model = model._model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([40, 2048, 7, 7])\n",
      "torch.Size([1320, 2048, 7, 7]) tensor(0.) tensor(11.8571)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(output.shape)\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet_robust_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./model_features/resnet_robust_eps1_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainscore_vision.model_helpers.check_submission import check_models\n",
    "from brainscore_vision.model_helpers.activations.pytorch import PytorchWrapper\n",
    "from brainscore_vision.model_helpers.activations.pytorch import load_preprocess_images\n",
    "from brainscore_vision.model_helpers.s3 import load_weight_file\n",
    "import functools\n",
    "import torch\n",
    "import os\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "\n",
    "\n",
    "def get_model(name):\n",
    "    \"\"\"\n",
    "    This method fetches an instance of a base model. The instance has to be callable and return a xarray object,\n",
    "    containing activations. There exist standard wrapper implementations for common libraries, like pytorch and\n",
    "    keras. Checkout the examples folder, to see more. For custom implementations check out the implementation of the\n",
    "    wrappers.\n",
    "    :param name: the name of the model to fetch\n",
    "    :return: the model instance\n",
    "    \"\"\"\n",
    "    assert name == 'resnet50_robust_l2_eps3'\n",
    "\n",
    "    model = resnet50()\n",
    "    weights_path = load_weight_file(bucket=\"brainscore-storage\", folder_name=\"brainscore-vision/models\",\n",
    "                                   relative_path=\"resnet50_robust_l2_eps3/imagenet_l2_3_0.pt\",\n",
    "                                   version_id=\"null\",\n",
    "                                   sha1=\"cc6e4441abc8ad6d2f4da5db84836e544bfb53fd\")\n",
    "    sd = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "    sd_processed = {}\n",
    "    for k, v in sd['model'].items():\n",
    "        if ('attacker' not in k) and ('model' in k):\n",
    "            sd_processed[k[13:]] = v \n",
    "    model.load_state_dict(sd_processed)\n",
    "    preprocessing = functools.partial(load_preprocess_images, image_size=224)\n",
    "    wrapper = PytorchWrapper(identifier='resnet50_robust_l2_eps3', model=model, preprocessing=preprocessing)\n",
    "    wrapper.image_size = 224\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "brainscore-storage/brainscore-vision/models/resnet50_robust_l2_eps3/imagenet_l2_3_0.pt: 100%|██████████| 205M/205M [00:04<00:00, 48.7MB/s] \n",
      "/tmp/ipykernel_2235464/1250554057.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(weights_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model('resnet50_robust_l2_eps3')\n",
    "model = model._model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 2048, 7, 7])\n",
      "torch.Size([40, 3, 224, 224])\n",
      "torch.Size([40, 2048, 7, 7])\n",
      "torch.Size([1320, 2048, 7, 7]) tensor(0.) tensor(25.0025)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Adjust as needed\n",
    "data_loader = DataLoader(TensorDataset(dataset_transformed), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "output_features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(output.shape)\n",
    "    output_features.append(output)\n",
    "\n",
    "hook = model.layer4[0].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        images = batch[0]\n",
    "        print(images.shape)\n",
    "        _ = model(images)\n",
    "        # break\n",
    "\n",
    "hook.remove()\n",
    "\n",
    "output_features = torch.cat(output_features, dim=0)\n",
    "print(output_features.shape, output_features.min(), output_features.max())\n",
    "np.save('./model_features/resnet_robust_eps3_features.npy', output_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symmetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
